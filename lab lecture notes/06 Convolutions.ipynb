{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf066a04-ea95-4d5d-a021-bb37d9392bff",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Image Filtering\n",
    "**Convolution** is a mathematical operation, using the data and the kernel.\n",
    "A kernel is a small matrix usually of odd dimensions that contains some numbers and these numbers are multiplied by the values of our input.\n",
    "\n",
    "You can use well defined kernels by OpenCV or by defining your own kernel.\n",
    "The output of a kernel **is not invertible**. (e.g if you blur an image, you cannot recover the original image using the blurred image). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68cf523-3779-4327-b86b-fe6e9d29cf1f",
   "metadata": {},
   "source": [
    "There is at least a filter on each operation you can do.\n",
    "Some filters are pairs of smaller filters. You can mix and match them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417e1fef-9b4c-4d8e-a630-e14f51152dea",
   "metadata": {},
   "source": [
    "What is the structure of a filter? You can apply convolution on any data that can be represented as a matrix. The kernel is **always a 3x3 matrix**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a21f867-d270-4b2e-bc51-98a1788f08ce",
   "metadata": {},
   "source": [
    "The **dot product** is the mathematical operation behind convolution. The output of a convolution is a smaller image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb797bb7-2d2f-464e-a8eb-2ac23c8a2fc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8ff1383-ab6d-4473-a86e-07d4c5d73785",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_kernel = np.array([\n",
    "    [1,0,1],\n",
    "    [1,0,1],\n",
    "    [1,0,1],\n",
    "])\n",
    "\n",
    "img = cv2.imread('C:/Users/USER/Desktop/AI Lab/Data/01-Data/lena.png')\n",
    "\n",
    "filtered_img = cv2.filter2D(img,-1, my_kernel) #2nd input is the number of channels, -1 means use all of them\n",
    "\n",
    "cv2.imshow('Result', filtered_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1088497-bac9-423e-bb19-ccf0155bd6b8",
   "metadata": {},
   "source": [
    "### Averaging filters\n",
    "Is a filter whose kernel computes the average of the pixels of the image that we are analyzing. \n",
    "If you do the average, you are blurring the image. \n",
    "There are several types of blur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6aec38f-e33a-4f52-a243-f62f207cfae7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('C:/Users/USER/Desktop/AI Lab/Data/01-Data/salt_pepper.png')\n",
    "\n",
    "filtered_img = cv2.blur(img,(3,3)) #(input image, kernel size)\n",
    "\n",
    "# filtered_img = cv2.blur(img,(7,3)) \n",
    "# a bigger kernel results in more blur since the average was done between a bigger number of pixels.\n",
    "\n",
    "# filtered_img = cv2.boxFilter(img,(3,3)) #(input image, kernel size) \n",
    "# there are some functions who need you to specify just 1 dimension of the kernel since the kernel has to be square. \n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Result', filtered_img) #the resulting image is smaller and has less noise\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf8e598-562d-46a6-8659-e53d19a4d406",
   "metadata": {},
   "source": [
    "#### Other types of blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e04c9ced-d0b3-4d5b-b72b-4967185e1705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_img = cv2.GaussianBlur(img, (3,3), 1, 1)\n",
    "filtered_img = cv2.medianBlur(img, 3) #careful here! just one dimensione specified\n",
    "# the median blur removes the salt and pepper noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943f5956-a88f-46aa-b6e2-a2864e7e4b9b",
   "metadata": {},
   "source": [
    "### Sharpening filters\n",
    "They try to do the opposite of blurring.\n",
    "Two ways.\n",
    "1. Blurred image + original image (Unsharpen Mask)\n",
    "2. Use a specific kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4748b3a-3745-4b96-8e57-3d1da25e53c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FIRST APPROACH (Unsharpen mask)\n",
    "img = cv2.imread('C:/Users/USER/Desktop/AI Lab/Data/01-Data/lena.png')\n",
    "\n",
    "smoothed_img = cv2.GaussianBlur(img,(9,9),10)\n",
    "final_img = cv2.addWeighted(img, 1.5, smoothed_img, -0.5, 0)\n",
    "\n",
    "#it sums two images together (1st img, weight of that image, 2nd image, weight of that image, gamma)\n",
    "# gamma's purpose is to fix the colors\n",
    "# weight of the image is a.k.a the \"importance\" or the \"dominance\" of that image.\n",
    "\n",
    "cv2.imshow('Original',img)\n",
    "cv2.imshow('Result',final_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e59d891f-b9df-4780-bb03-34ef978a9843",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SECOND APPROACH\n",
    "# There is a well known kernel\n",
    "sharpen_kernel = np.array([\n",
    "    [0,-1,0],\n",
    "    [-1,5,-1],\n",
    "    [0,-1,0],\n",
    "])\n",
    "\n",
    "final_img = cv2.filter2D(img, -1, sharpen_kernel) #if you get a black image, smth is wrong with the kernel\n",
    "\n",
    "cv2.imshow('Original',img)\n",
    "cv2.imshow('Result',final_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26c7543-c925-4e7e-b860-89b760d3da0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Using filters to extract information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5a53ed-7c7c-484f-b4fd-f2e0799be5e3",
   "metadata": {},
   "source": [
    "#### Extracting contours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be130ee-9d39-46b4-a4cb-e02e1beb9e52",
   "metadata": {},
   "source": [
    "The edges are **the derivatives** of the image. a.ka. points of extreme change in colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b024c49-fccd-490e-8918-ed9b9823f102",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#img = cv2.imread('C:/Users/USER/Desktop/AI Lab/Data/01-Data/lena.png', cv2.IMREAD_GRAYSCALE) #to load the image in grayscale\n",
    "#flags are integers, so you can put 0 instead as a 2nd argument\n",
    "\n",
    "img = cv2.imread('C:/Users/USER/Desktop/AI Lab/Data/01-Data/lena.png')\n",
    "\n",
    "#Converting at runtime an image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# compute the derivatives for both axis\n",
    "grad_x = cv2.Sobel(gray, -1, 1, 0) # (img, channels, x axis, y axis). 1 means compute on this axis. \n",
    "grad_y = cv2.Sobel(gray, -1, 0, 1)\n",
    "\n",
    "# make the values positive and then scale them to the range [0,255] \n",
    "abs_x = cv2.convertScaleAbs(grad_x)\n",
    "abs_y = cv2.convertScaleAbs(grad_y)\n",
    "\n",
    "# merge the two derivatives into a single image \n",
    "grad = cv2.addWeighted(abs_x, 0.5, abs_y, 0.5, 0)\n",
    "\n",
    "cv2.imshow('Result', grad)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7374695-c1dd-484a-a4bf-d8738948dcd8",
   "metadata": {},
   "source": [
    "**Laplacian filter** -> apply the above procedure another time (twice in total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75b72770-bc8f-4048-9855-901a56c4ac9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use the laplacian instead\n",
    "\n",
    "abs = cv2.Laplacian(gray, -1,(3,3)) #image, nr channels, kernel size\n",
    "abs_scaled = cv2.convertScaleAbs(abs)\n",
    "\n",
    "cv2.imshow('Result', abs)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
